{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.7 64-bit ('venv')",
      "metadata": {
        "interpreter": {
          "hash": "d079569ca84252866d5d1a0bb8259f4fceb05e3976e3d53cbeeb02ca257578df"
        }
      }
    },
    "colab": {
      "name": "AI_Platform_(Unified)_MB_SDK_Metric/Parameters_visualization_for_managed_pipeline_jobs .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snm88Z0sROQB"
      },
      "source": [
        "# Copyright 2021 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThTHoy7DRSye"
      },
      "source": [
        "## Feedback or issues?\n",
        "\n",
        "Let us know if you have any [feedback or questions](https://forms.gle/hXDnv1T4WanMwTi79). If you provide an email address, we will follow up with you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acg-u47CJ7-T"
      },
      "source": [
        "# Visualizing a pipeline run's parameters and metrics using the Model Builder SDK\n",
        "\n",
        "To use this Jupyter notebook, copy the notebook to an AI Platform (Unified) Notebooks instance with Tensorflow installed and open it. You can run each step, or cell, and see its results. To run a cell, use Shift+Enter. Jupyter automatically displays the return value of the last line in each cell. For more information about running notebooks in AI Platform (Unified) Notebook, see the [AI Platform (Unified) Notebook guide](https://cloud.google.com/ai-platform-unified/docs/general/notebooks).\n",
        "\n",
        "\n",
        "This notebook demonstrates how to extract and visualize parameters and metrics for pipeline runs created using AI Platform (Unified) Pipelines.\n",
        "\n",
        "\n",
        "\n",
        "Note: You might incur charges for training, prediction, storage or usage of other Google Cloud products in connection with running this example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amZxHeNzRhgN"
      },
      "source": [
        "## Setting up\n",
        "\n",
        "This notebook is intended to be run in the following environments:\n",
        "\n",
        "* [AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks). \n",
        "* [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb)\n",
        "\n",
        "If you haven't already enabled the AI Platform API, on the [AI Platform (Unified) Dashboard](https://console.cloud.google.com/ai/platform) page in the Google Cloud Console, click **Enable the AI Platform API**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr7SU9yVhCGk"
      },
      "source": [
        "Set `gcloud` to use your project.  **Edit the following cell before running it**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtIjHUhlJ7-W"
      },
      "source": [
        "PROJECT_ID = 'your-project-id'  # <---CHANGE THIS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW2xy31bSC9G"
      },
      "source": [
        "!gcloud config set project {PROJECT_ID}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpA3HT_ZhI5u"
      },
      "source": [
        "If you're running this notebook on colab, authenticate with your user account:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjLd9x994wm3"
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VL5avdUJ7-V"
      },
      "source": [
        "### Install the Model Builder SDK and the Kubeflow Pipelines SDK\n",
        "\n",
        "Use the instructions in this section to install the Model Builder SDK and the Kubeflow Pipelines SDK.\n",
        "\n",
        "After you install the SDKs, the kernel is be automatically restarted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnM0lyhRUdRP"
      },
      "source": [
        "!gsutil cp gs://cloud-aiplatform-pipelines/releases/latest/kfp-1.5.0rc5.tar.gz .\n",
        "!gsutil cp gs://cloud-aiplatform-pipelines/releases/latest/aiplatform_pipelines_client-0.1.0.caip20210415-py3-none-any.whl ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c4l9EWnYLfY"
      },
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  USER_FLAG = ''\n",
        "else:\n",
        "  USER_FLAG = '--user'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9dJ5Of-dORl"
      },
      "source": [
        "!python3 -m pip install {USER_FLAG} kfp-1.5.0rc5.tar.gz --upgrade\n",
        "!python3 -m pip install {USER_FLAG} aiplatform_pipelines_client-0.1.0.caip20210415-py3-none-any.whl --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-SAVo4cht68"
      },
      "source": [
        "Install the Model Builder SDK and restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-6l0OdRJ7-V"
      },
      "source": [
        "%%capture\n",
        "!pip3 uninstall -y google-cloud-aiplatform\n",
        "!pip3 install --user git+https://github.com/googleapis/python-aiplatform.git@dev-test \n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N33S1ikHIOPS"
      },
      "source": [
        "Check the version of the Kubeflow Pipelines SDK. It should be >= 1.6.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4uvTyimMYOr"
      },
      "source": [
        "# Check the KFP version\n",
        "!python3 -c \"import kfp; print('KFP version: {}'.format(kfp.__version__))\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1GX5KDOUJuI"
      },
      "source": [
        "If you're on colab, re-authorize after the kernel restart. **Edit the following cell for your project ID before running it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsWNUkdPYt3_"
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  PROJECT_ID = 'your-project-id'  # <---CHANGE THIS\n",
        "  !gcloud config set project {PROJECT_ID}\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  USER_FLAG = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tskC13YxW7b3"
      },
      "source": [
        "### Set some variables\n",
        "\n",
        "**Before you run the next cell**, **edit it** to set variables for your project. For `BUCKET_NAME`, enter the name of a Cloud Storage bucket in your project.  Don't include the `gs://` prefix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ4LJ2pcY53A"
      },
      "source": [
        "# Required Parameters\n",
        "USER = 'your-user-name' # <---CHANGE THIS\n",
        "BUCKET_NAME = 'your-bucket-name'  # <---CHANGE THIS\n",
        "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(BUCKET_NAME, USER)\n",
        "\n",
        "PROJECT_ID = 'your-project-id'  # <---CHANGE THIS\n",
        "REGION = 'us-central1'\n",
        "API_KEY = 'your-api-key'  # <---CHANGE THIS\n",
        "\n",
        "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMAK6NrNiVR6"
      },
      "source": [
        "### Initialize Model Builder SDK\n",
        "\n",
        "Initialize the *client* for AI Platform (Unified)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC9qKm4aiVR7"
      },
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8XbvBUVqjV4"
      },
      "source": [
        "## Define and run a pipeline that tracks metrics\n",
        "\n",
        "In this section you will define and run a simple pipeline that tracks parameters and metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk5ziMTYxxMc"
      },
      "source": [
        "from typing import NamedTuple\n",
        "from kfp.v2 import dsl\n",
        "from kfp.v2.dsl import (\n",
        "    component,\n",
        "    InputPath,\n",
        "    OutputPath,\n",
        "    InputArtifact,\n",
        "    OutputArtifact,\n",
        "    Artifact,\n",
        "    Dataset,\n",
        "    Model,\n",
        "    ClassificationMetrics,\n",
        "    Metrics,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnS0ki2Y-TeI"
      },
      "source": [
        "Define a simple Python function-based component that uses scikit-learn to train a model using some input parameters and produces an accuracy metric. The accuracy metric is logged in the `metrics` output artifact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A6ESdmsx2ak"
      },
      "source": [
        "@component(\n",
        "    packages_to_install=['sklearn'],\n",
        "    base_image='python:3.9',\n",
        ")\n",
        "\n",
        "def digit_classification(input_seed: int, split_count: int, metrics: Output[Metrics]):\n",
        "  from sklearn import model_selection\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn import datasets\n",
        "  from sklearn.metrics import accuracy_score\n",
        "\n",
        "  # Load digits dataset\n",
        "  iris = datasets.load_iris()\n",
        "  \n",
        "  # # Create feature matrix\n",
        "  X = iris.data\n",
        "  \n",
        "  # Create target vector\n",
        "  y = iris.target\n",
        "  \n",
        "  #test size\n",
        "  test_size = 0.20\n",
        "  \n",
        "  #cross-validation settings\n",
        "  kfold = model_selection.KFold(n_splits=split_count, random_state=input_seed, shuffle=True)\n",
        "  \n",
        "  #Model instance\n",
        "  model = LogisticRegression()\n",
        "  scoring = 'accuracy'\n",
        "  results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
        "  \n",
        "  #split data\n",
        "  X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size, random_state=input_seed)\n",
        "  #fit model\n",
        "  model.fit(X_train, y_train)\n",
        "  \n",
        "  #accuracy on test set\n",
        "  result = model.score(X_test, y_test)\n",
        "  metrics.get().log_metric('accuracy', (result*100.0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe-tMinW-zsF"
      },
      "source": [
        "Define a pipeline that uses the `digit_classification` component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7r1SQ9aypFb"
      },
      "source": [
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root='gs://ml-pipeline-artifacts/v2-artifacts',\n",
        "    # A name for the pipeline. Use to determine the pipeline Context.\n",
        "    name='metrics-pipeline-v2')\n",
        "def pipeline(seed: int, splits: int):\n",
        "  digit_classification_op = digit_classification(input_seed=seed, split_count=splits)\n",
        "\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "  from kfp.v2 import compiler\n",
        "  from aiplatform.pipelines import client  \n",
        "\n",
        "  compiler.Compiler().compile(pipeline_func=pipeline,                                                     \n",
        "                              package_path='metrics_pipeline.json')\n",
        "\n",
        "  \n",
        "\n",
        "  api_client = client.Client(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    api_key=API_KEY)\n",
        "\n",
        "  response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path='metrics_pipeline.json',\n",
        "    pipeline_root=PIPELINE_ROOT,  # Override if needed.\n",
        "    parameter_values={'seed': 8, 'splits': 11})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8uiPAESi5Fe"
      },
      "source": [
        "Try to changing the `seed` and `splits` values and rerunning the cell above to create multiple pipeline runs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6aoqOBtiCQH"
      },
      "source": [
        "## Comparing the parameters and metrics of pipeline runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvkkfOYBnqUk"
      },
      "source": [
        "In this section, you use the Model Builder SDK to compare the parameters and metrics of the pipeline runs you created in the previous section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwyJWM62xC0a"
      },
      "source": [
        "### Extract metrics and parameters into a pandas dataframe for run comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKXW_8ByiCQI"
      },
      "source": [
        "pipeline_df = aiplatform.get_pipeline_df(pipeline=\"metrics-pipeline-v2\")\n",
        "pipeline_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1fMi2wtxI9j"
      },
      "source": [
        "### Parallel coordinates plot of parameters and metrics\n",
        "\n",
        "With the metric and parameters in a dataframe, you can perform further analysis to exetract useful information. The following example compares data from each run using a parallel coordinate plot. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_WqXRTkiCQJ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [15, 5]\n",
        "\n",
        "pipeline_df['param.input:seed'] = pipeline_df['param.input:seed'].astype(np.float16)\n",
        "pipeline_df['param.input:splits'] = pipeline_df['param.input:splits'].astype(np.float16) \n",
        "\n",
        "ax = pd.plotting.parallel_coordinates(\n",
        "    pipeline_df.reset_index(level=0),\n",
        "    'run_name', cols=['param.input:seed','param.input:splits', 'metric.accuracy'],\n",
        "    # color=['blue', 'green', 'pink', 'red'],\n",
        "    )\n",
        "ax.set_yscale('symlog')\n",
        "ax.legend(bbox_to_anchor=(1.0, 0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XngGKqmkxBqm"
      },
      "source": [
        "## Define and run a pipeline that tracks complex metrics\n",
        "\n",
        "In addition to basic key/value pair metrics, you can also track more complex metrics and use Model Builder SDK to visualize those metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW9EmIXmYLa6"
      },
      "source": [
        "The following example defines a Python function-based component that uses scikit-learn to train a classifier and produce evaluations that can be visualized. This example shows how to visualize an receiver operating characteristic (ROC) curve.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ_kXbhCUEUN"
      },
      "source": [
        "@component(\n",
        "    packages_to_install=['sklearn'],\n",
        "    base_image='python:3.9',\n",
        ")\n",
        "def wine_classification(metrics: Output[ClassificationMetrics]):\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import roc_curve\n",
        "    from sklearn.datasets import load_wine\n",
        "    from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "\n",
        "    X, y = load_wine(return_X_y=True)\n",
        "    # Binary classification problem for label 1.\n",
        "    y = y == 1\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "    rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "    rfc.fit(X_train, y_train)\n",
        "    y_scores = cross_val_predict(rfc, X_train, y_train, cv=3, method='predict_proba')\n",
        "    y_predict = cross_val_predict(rfc, X_train, y_train, cv=3, method='predict')\n",
        "    fpr, tpr, thresholds = roc_curve(y_true=y_train, y_score=y_scores[:,1], pos_label=True)\n",
        "    metrics.get().log_roc_curve(fpr, tpr, thresholds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "289jqF_XUEUO"
      },
      "source": [
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root='gs://ml-pipeline-artifacts/v2-artifacts',\n",
        "    # A name for the pipeline. Use to determine the pipeline Context.\n",
        "    name='metrics-roc-pipeline-v2')\n",
        "def pipeline():\n",
        "  wine_classification_op = wine_classification()  \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  from kfp.v2 import compiler\n",
        "  from aiplatform.pipelines import client  \n",
        "\n",
        "  compiler.Compiler().compile(pipeline_func=pipeline,                                                     \n",
        "                              package_path='metrics_pipeline.json')\n",
        "\n",
        "  \n",
        "\n",
        "  api_client = client.Client(\n",
        "    project_id=PROJECT_ID,\n",
        "    region='us-central1',\n",
        "    api_key=API_KEY)\n",
        "\n",
        "  response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path='metrics_pipeline.json',\n",
        "    pipeline_root=PIPELINE_ROOT,  # Override if needed.\n",
        "    parameter_values={})\n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFWIJUsSOSRe"
      },
      "source": [
        "### Plot ROC curve and calculate AUC number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcmCKVOKQLT-"
      },
      "source": [
        "In addition to basic metrics, you can extract complex metrics and perform further analysis using the `get_pipeline_df` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rswujUa4wpB3"
      },
      "source": [
        "pipeline_df = aiplatform.get_pipeline_df(pipeline=\"metrics-roc-pipeline-v2\")\n",
        "pipeline_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqo-GgBuwyrn"
      },
      "source": [
        "df = pd.DataFrame(pipeline_df['metric.confidenceMetrics'][0])\n",
        "auc = np.trapz(df['recall'],df['falsePositiveRate'])\n",
        "plt.plot(df['falsePositiveRate'],df['recall'], label=\"auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}