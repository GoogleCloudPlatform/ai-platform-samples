{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64f79fe18b56"
      },
      "outputs": [],
      "source": [
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "289934e795d0"
      },
      "source": [
        "# Cascade (HD-CNN Model Deriative)\n",
        "\n",
        "## Objective\n",
        "\n",
        "This notebook demonstrates building a hierachical image classifer based on a HD-CNN deriative which uses cascading classifers to predict the class of a label from a coarse to finer classes. \n",
        "\n",
        "In this demonstration, we have two classes in the heirarchy: fruits and varieties of fruit. The model will first predict the coarse class (type of fruit) and then within that class of fruit, the variety. For example, if given an image of Apple Granny Smith, it would first predict 'Apple' (fruit) and then predict the 'Apple Granny Smith'.\n",
        "\n",
        "This deriative of the HD-CNN is designed to demonstrate both the methodology of heirarchical classification, as well as design improvements not available at the time (2014) when the model was first published [Zhicheng Yan](https://arxiv.org/abs/1410.0736).\n",
        "\n",
        "### General Approach\n",
        "\n",
        "Our HD-CNN deriative archirecture consists of:\n",
        "\n",
        "    1. An stem convolutional block.\n",
        "        - The output from the stem convolutional head is shared with the coarse and finer classifiers \n",
        "        (referred to as the shared layers in the paper).\n",
        "    2. A coarse classifier.\n",
        "        - A Convolution and Dense layers for classifying the coarse level class. \n",
        "    3. A set of finer classifiers, one per coarse level class.\n",
        "        - A Convolution and Dense layers per coarse level class for classifying the corresponding finer \n",
        "        level class.\n",
        "    4. A conditional execution step for predicting a specific finer classifier based on the output of the \n",
        "       coarse classifier.\n",
        "        - The coarse level classifier is predicted.\n",
        "        - The index of the prediction is used to select a finer classifier.\n",
        "        - An im-memory copy of the shared bottleneck layer (i.e., last convolution layer in stem) is passed as the\n",
        "          input to the finer level classifier.\n",
        "    \n",
        "\n",
        "Our HD-CNN deriative is trained as follows:\n",
        "\n",
        "    1. Train the coarse level classifier using the coarse level labels in the dataset.\n",
        "    \n",
        "<img src='arch-1.png'>\n",
        "    \n",
        "    2. Train the finer level classifier per coarse level class, using the corresponding subset (with finer\n",
        "       labels) from the dataset.\n",
        "       \n",
        "<img src='arch-2.png'>\n",
        "\n",
        "<br/>      \n",
        "## Dataset\n",
        "\n",
        "We will be using the Fruits-360 dataset, which was formerly a Kaggle competition. It consists of images of fruit labeled by fruit type and the variety. \n",
        "\n",
        "    1. There are a total of 47 types of fruit (e.g., Apple, Orange, Pear, etc) and 81 varieties.\n",
        "    2. On average, there are 656 images per variety.\n",
        "    3. Each image is 128x128 RGB.\n",
        "    \n",
        "<div>\n",
        "<img src='Training/Apple/Apple Golden 2/0_100.jpg' style='float: left'>\n",
        "<img src='Training/Apple/Apple Red 1/0_100.jpg'  style='float: left'>\n",
        "<img src='Training/Apple/Apple Red 1/0_100.jpg' style='float: left'>\n",
        "<img src='Training/Orange/Orange/0_100.jpg' style = 'float: left'>\n",
        "<img src='Training/Pear/Pear/0_100.jpg' style = 'float: left'>\n",
        "</div>\n",
        "\n",
        "\n",
        "## Objective\n",
        "\n",
        "The objective is to train a hierarchical image classifier (coarse and then finer label) using a cascading layer architecture. First, the shared layers and coarse classifier are trained. Then the cascading finer classifiers are trained. \n",
        "\n",
        "For prediction, the outcome (softmax) of the coarse classifier will conditionally execute the corresponding finer classifier and reuse the feature maps from the shared layers.\n",
        "\n",
        "## Costs\n",
        "\n",
        "This notebook requires 17GB of memory. It will not run on a Standard TF JaaS instance (15GB). You will need to select an instance with memory > 17GB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2c05e6dd9fd"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Download the Fruits 360 dataset from GCS public bucket into this JaaS instance.\n",
        "\n",
        "Some of the cells in the notebook display images. The images will not appear until the cell for copying the training data/misc from GCS into the JaaS instance is executed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38d0eeeee9ae"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://cloud-samples-data/air/fruits360/fruits360-combined.zip .\n",
        "!ls\n",
        "!unzip -qn fruits360-combined.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "270ffb09c839"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "We will be using the fully frameworks and Python modules:\n",
        "\n",
        "    1. Keras framework for building and training models.\n",
        "    2. Keras builtin models (resnet50).\n",
        "    3. Keras preprocessing for feeding and augmenting the dataset during training.\n",
        "    4. Gap data engineering framework for preprocessing the image data.\n",
        "    5. Numpy for general image/matrix manipulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f4aa317b40d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import cv2\n",
        "import keras.layers as layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import Input, Model, Sequential, optimizers\n",
        "from keras.applications.resnet50 import (ResNet50, decode_predictions,\n",
        "                                         preprocess_input)\n",
        "from keras.layers import (BatchNormalization, Conv2D, Dense, Dropout, Flatten,\n",
        "                          GlobalAveragePooling2D, MaxPooling2D, ReLU)\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d0ef14eece6"
      },
      "source": [
        "## Make Datasets\n",
        "\n",
        "### Make Coarse Category Dataset\n",
        "\n",
        "This makes the by fruit type dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b657ccff32ad"
      },
      "outputs": [],
      "source": [
        "def Fruits(root):\n",
        "    n_label = 0\n",
        "    images = []\n",
        "    labels = []\n",
        "    classes = {}\n",
        "\n",
        "    os.chdir(root)\n",
        "    classes_ = os.scandir(\"./\")\n",
        "    for class_ in classes_:\n",
        "        print(class_.name)\n",
        "        os.chdir(class_.name)\n",
        "        classes[class_.name] = n_label\n",
        "\n",
        "        # Finer Level Subdirectories per Coarse Level\n",
        "        subclasses = os.scandir(\"./\")\n",
        "        for subclass in subclasses:\n",
        "            os.chdir(subclass.name)\n",
        "            files = os.listdir(\"./\")\n",
        "            for file in files:\n",
        "                image = cv2.imread(file)\n",
        "                images.append(image)\n",
        "                labels.append(n_label)\n",
        "\n",
        "            os.chdir(\"../\")\n",
        "\n",
        "        os.chdir(\"../\")\n",
        "        n_label += 1\n",
        "    os.chdir(\"../\")\n",
        "    images = np.asarray(images)\n",
        "    images = (images / 255.0).astype(np.float32)\n",
        "    labels = to_categorical(labels, n_label)\n",
        "    print(\"Images\", images.shape, \"Labels\", labels.shape, \"Classes\", classes)\n",
        "\n",
        "    # Split the processed image dataset into training and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        images, labels, test_size=0.20, shuffle=True\n",
        "    )\n",
        "    return x_train, x_test, y_train, y_test, classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50660f3e8a5e"
      },
      "source": [
        "### Make Finer Category Datasets\n",
        "\n",
        "This makes the by Fruit Variety datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e13c3ca35c81"
      },
      "outputs": [],
      "source": [
        "def Varieties(root):\n",
        "    \"\"\" Generate Cascade (Finer) Level Dataset for Fruit Varieties\"\"\"\n",
        "\n",
        "    datasets = {}\n",
        "\n",
        "    os.chdir(root)\n",
        "    fruits = os.scandir(\"./\")\n",
        "    for fruit in fruits:\n",
        "        n_label = 0\n",
        "        images = []\n",
        "        labels = []\n",
        "        classes = {}\n",
        "        print(\"FRUIT\", fruit.name)\n",
        "        os.chdir(fruit.name)\n",
        "        varieties = os.scandir(\"./\")\n",
        "        for variety in varieties:\n",
        "            print(\"VARIETY\", variety.name)\n",
        "            classes[variety.name] = n_label\n",
        "            os.chdir(variety.name)\n",
        "            files = os.listdir(\"./\")\n",
        "            for file in files:\n",
        "                image = cv2.imread(file)\n",
        "                images.append(image)\n",
        "                labels.append(n_label)\n",
        "            os.chdir(\"../\")\n",
        "            n_label += 1\n",
        "        images = np.asarray(images)\n",
        "        images = (images / 255.0).astype(np.float32)\n",
        "        labels = to_categorical(labels, n_label)\n",
        "        x_train, x_test, y_train, y_test = train_test_split(\n",
        "            images, labels, test_size=0.20, shuffle=True\n",
        "        )\n",
        "        datasets[fruit.name] = (x_train, x_test, y_train, y_test, classes)\n",
        "        os.chdir(\"../\")\n",
        "        print(\"IMAGES\", x_train.shape, y_train.shape, \"CLASSES\", classes)\n",
        "    os.chdir(\"../\")\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18683796fd65"
      },
      "source": [
        "### Generate the preprocessed Coarse Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a03382411ab"
      },
      "outputs": [],
      "source": [
        "!free -m\n",
        "x_train, x_test, y_train, y_test, fruits_classes = Fruits(\"Training\")\n",
        "!free -m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e84aab3e7192"
      },
      "source": [
        "### Split Coarse Dataset (by Fruit) into Train, Validation and Test\n",
        "\n",
        "First split into train and test. Then split out 10% of train to use for validation during training.\n",
        "\n",
        "    - Train: 80%\n",
        "        - Train: 90%\n",
        "        - Validation: 10%\n",
        "    - Test : 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d0573218a8f"
      },
      "outputs": [],
      "source": [
        "# Split out 10% of Train to use for Validation\n",
        "pivot = int(len(x_train) * 0.9)\n",
        "x_val = x_train[pivot:]\n",
        "y_val = y_train[pivot:]\n",
        "x_train = x_train[:pivot]\n",
        "y_train = y_train[:pivot]\n",
        "\n",
        "print(\"train\", x_train.shape, y_train.shape)\n",
        "print(\"val  \", x_val.shape, y_val.shape)\n",
        "print(\"test \", x_test.shape, y_test.shape)\n",
        "!free -m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cecea7cac96"
      },
      "source": [
        "## Make Trainers\n",
        "\n",
        "Create the routines we will use for training.\n",
        "\n",
        "### Make Feeder\n",
        "\n",
        "Prepare the Feeder mechanism for training the neural networkm using ImageDataGenerator. \n",
        "\n",
        "Add image augmentation for:\n",
        "\n",
        "    1. Horizontal Flip\n",
        "    2. Verticial  Flip\n",
        "    3. Random Rotation +/- 30 degrees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85d4b400eaa7"
      },
      "outputs": [],
      "source": [
        "def Feeder():\n",
        "    datagen = ImageDataGenerator(\n",
        "        horizontal_flip=True, vertical_flip=True, rotation_range=30\n",
        "    )\n",
        "    return datagen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae9829153099"
      },
      "source": [
        "### Make Trainer\n",
        "\n",
        "Prepare a training session:\n",
        "\n",
        "    1. Epochs defaults to 10\n",
        "    2. Batch size defaults to 32\n",
        "    3. Train with validation data\n",
        "    4. Final evaluation with test data (holdout set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "997919414b10"
      },
      "outputs": [],
      "source": [
        "def Train(model, datagen, x_train, y_train, x_test, y_test, epochs=10, batch_size=32):\n",
        "    model.fit_generator(\n",
        "        datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True),\n",
        "        steps_per_epoch=len(x_train) / batch_size,\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        validation_data=(x_test, y_test),\n",
        "    )\n",
        "    scores = model.evaluate(x_train, y_train, verbose=1)\n",
        "    print(\"Train\", scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8266d4dd52f"
      },
      "source": [
        "## Make Model\n",
        "\n",
        "### Stem Convolutional Block (Base Model)\n",
        "\n",
        "We will use this base model as the stem convolutional block of cascading model:\n",
        "    1. The output of this model are a set of pooled feature maps.\n",
        "    2. The last layer that produces this set of pooled feature maps is referred to as the bottleneck layer.\n",
        "\n",
        "### Coarse Classifier\n",
        "\n",
        "The coarse classifier is an independent block layer for classifying the coarse level label:\n",
        "\n",
        "    1. Input is the bottleneck layer from the stem convolutional block.\n",
        "    2. Layer consists of a convolution layer and a dense layer, where the dense layer is the classifier.\n",
        "    \n",
        "### Finer Classifier\n",
        "\n",
        "The finer classifiers are a set of independent block layers for classifying the finer label. There is one finer classifier per unique coarse level label.\n",
        "\n",
        "    1. Input is the bottleneck layer from the stem convolutional block.\n",
        "    2. Layer consists of a convolution layer and a dense layer, where the dense layer is the classifier.\n",
        "    3. The finer classifer is conditionally executed based on the softmax output from the coarse classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcf63388e666"
      },
      "source": [
        "### ResNet for Transfer Learning\n",
        "\n",
        "Use a prebuilt Keras model (ResNet 50). Either as:\n",
        "\n",
        "    1. Transfer Learning: The layers are pretrained with imagenet weights.\n",
        "    2. Full Training: layers are not pretrained (weights = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17cebb3266cf"
      },
      "outputs": [],
      "source": [
        "def ResNet(shape=(128, 128, 3), nclasses=47, optimizer=\"adam\", weights=None):\n",
        "    base_model = ResNet50(weights=weights, include_top=False, input_shape=shape)\n",
        "\n",
        "    for i, layer in enumerate(base_model.layers):\n",
        "        # first: train only the top layers (which were randomly initialized) for Transfer Learning\n",
        "        if weights is not None:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # label the last convolutional layer in the base model as the bottleneck\n",
        "    layer.name = \"bottleneck\"\n",
        "\n",
        "    # Get the last convolutional layer of the ResNet base model\n",
        "    x = base_model.output\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # let's add a fully-connected layer\n",
        "    # x = Dense(1024, activation='relu')(x)\n",
        "    # and a logistic layer\n",
        "    predictions = Dense(nclasses, activation=\"softmax\")(x)\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # compile the model (should be done *after* setting layers to non-trainable)\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
        "    )\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04d297ee5a51"
      },
      "source": [
        "### Simple ConvNet\n",
        "\n",
        "The stem convolutional block consists of a mini-VGG, which consists of:\n",
        "\n",
        "    1. A convolutional input (stem)\n",
        "    2. Three convolutional groups, each doubling the number of filers.\n",
        "    3. Each convolutional group consists of one convolutional block.\n",
        "    4. A dropout of 50% is added to the first convolutional group.\n",
        "    \n",
        "The coarse classifier consists of:\n",
        "\n",
        "    1. A 1024 none dense layer\n",
        "    2. A 47 node dense layer for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77fd7b09c34f"
      },
      "outputs": [],
      "source": [
        "def ConvNet(shape=(128, 128, 3), nclasses=47, optimizer=\"adam\"):\n",
        "    model = Sequential()\n",
        "    # stem convolutional group\n",
        "    model.add(Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\", input_shape=shape))\n",
        "\n",
        "    # conv block - double filters\n",
        "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "    model.add(ReLU())\n",
        "    model.add(Dropout(0.50))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # conv block - double filters\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "    model.add(ReLU())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # conv block - double filters + bottleneck layer\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D((2, 2), name=\"bottleneck\"))\n",
        "\n",
        "    # dense block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation=\"relu\"))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # classifier\n",
        "    model.add(Dense(nclasses, activation=\"softmax\"))\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
        "    )\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d288748b4dd"
      },
      "source": [
        "## Start Training\n",
        "\n",
        "    1. Train the Coarse Classifier\n",
        "    2. Add Finer Classifiers\n",
        "    4. Train the Finer Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ba3a1042449"
      },
      "source": [
        "### Generate Coarse Model\n",
        "\n",
        "Choose between:\n",
        "\n",
        "    1. A untrained simple VGG CovNet as Stem Convolution Group, or\n",
        "    2. Pre-trained ResNet50 (imagenet weights) for Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94feaa0dbb2d"
      },
      "outputs": [],
      "source": [
        "# Select the model for the stem convolutional group (shared layers)\n",
        "stem = \"ConvNet\"\n",
        "if stem == \"ConvNet\":\n",
        "    model = ConvNet(shape=(100, 100, 3))\n",
        "elif stem == \"ResNet-imagenet\":\n",
        "    model = ResNet(weights=\"imagenet\", optimizer=\"adagrad\")\n",
        "elif stem == \"ResNet\":\n",
        "    model = ResNet()\n",
        "# load previously stored model\n",
        "else:\n",
        "    model = load_model(\"model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51dd58f6a2ca"
      },
      "source": [
        "### Train the Coarse Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "749cc66c9706"
      },
      "outputs": [],
      "source": [
        "datagen = Feeder()\n",
        "Train(model, datagen, x_train, y_train, x_val, y_val, 5)\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Test\", scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8da583f3bdee"
      },
      "source": [
        "### Save the Coarse Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fb33a4ab7bd"
      },
      "outputs": [],
      "source": [
        "# Save the model and weights\n",
        "model.save(\"model-coarse.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "513cf9a2ce5b"
      },
      "source": [
        "### Prepare Coarse CNN for cascade training\n",
        "\n",
        "    1. Freeze all layers\n",
        "    2. Find bottleneck layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b45c4aae518f"
      },
      "outputs": [],
      "source": [
        "def Bottleneck(model):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "        if layer.name == \"bottleneck\":\n",
        "            bottleneck = layer\n",
        "\n",
        "    print(\"BOTTLENECK\", bottleneck.output.shape)\n",
        "    return bottleneck"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f44f30353db5"
      },
      "source": [
        "### Generate the preprocessed Finer Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20fca39bed54"
      },
      "source": [
        "### Split Finer (by Variety) Datasets into Train, Validation and Test\n",
        "\n",
        "    1. For each fruit type, split the corresponding variety images into train, validation and test.\n",
        "    2. Save each split dataset in a dictionary, using the fruit name as the key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6bd815fdd49"
      },
      "outputs": [],
      "source": [
        "# Converse memory by releasing training data for coarse model\n",
        "import gc\n",
        "\n",
        "x_train = y_train = x_val = y_val = x_test = y_test = None\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e41458957d94"
      },
      "outputs": [],
      "source": [
        "varieties_datasets = Varieties(\"Training\")\n",
        "for key, dataset in varieties_datasets.items():\n",
        "\n",
        "    _x_train, _x_test, _y_train, _y_test, classes = dataset\n",
        "\n",
        "    # Separate out 10% of train for validation\n",
        "    pivot = int(len(_x_train) * 0.9)\n",
        "    _x_val = _x_train[pivot:]\n",
        "    _y_val = _y_train[pivot:]\n",
        "    _x_train = _x_train[:pivot]\n",
        "    _y_train = _y_train[:pivot]\n",
        "\n",
        "    # save the dataset for this fruit (key)\n",
        "    varieties_datasets[key] = {\n",
        "        \"classes\": classes,\n",
        "        \"train\": (_x_train, _y_train),\n",
        "        \"val\": (_x_val, _y_val),\n",
        "        \"test\": (_x_test, _y_test),\n",
        "    }\n",
        "\n",
        "!free -m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66e9faa4657f"
      },
      "source": [
        "### Add Each Cascade (Finer) Classifier\n",
        "\n",
        "    1. Get the bottleneck layer for the coarse CNN\n",
        "    2. Add an independent finer classifier per fruit from the bottleneck layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cc02714a29a"
      },
      "outputs": [],
      "source": [
        "bottleneck = Bottleneck(model)\n",
        "cascades = []\n",
        "for key, val in varieties_datasets.items():\n",
        "    classes = val[\"classes\"]\n",
        "    print(\"KEY\", key, classes)\n",
        "    # if only one subclassifier, then skip (i.e., coarse == finer)\n",
        "    if len(classes) == 1:\n",
        "        continue\n",
        "    x = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(bottleneck.output)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Flatten()(bottleneck.output)\n",
        "    x = layers.Dense(1024, activation=\"relu\")(x)\n",
        "    x = layers.Dense(len(classes), activation=\"softmax\", name=key.replace(\" \", \"\"))(x)\n",
        "    cascades.append(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1279cabb1be"
      },
      "source": [
        "### Compile each finer classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9e7c8aa6643"
      },
      "outputs": [],
      "source": [
        "classifiers = []\n",
        "for cascade in cascades:\n",
        "    _model = Model(model.input, cascade)\n",
        "    _model.compile(\n",
        "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    _model.summary()\n",
        "    classifiers.append(_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74bb328d22cb"
      },
      "source": [
        "### Train the finer classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b6e4e23f243"
      },
      "outputs": [],
      "source": [
        "for classifier in classifiers:\n",
        "    # get the output layer for this subclassifier\n",
        "    last = classifier.layers[len(classifier.layers) - 1]\n",
        "    print(last, last.name)\n",
        "\n",
        "    # find the corresponding variety dataset\n",
        "    for key, dataset in varieties_datasets.items():\n",
        "        if key == last.name:\n",
        "            x_train, y_train = dataset[\"train\"]\n",
        "            x_val, y_val = dataset[\"val\"]\n",
        "\n",
        "            datagen = Feeder()\n",
        "            Train(classifier, datagen, x_train, y_train, x_val, y_val, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8146a8f4ceab"
      },
      "source": [
        "### Evaluate the Model\n",
        "\n",
        "    1. Evaluate the Model for each finer classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7e59c39ea6e"
      },
      "outputs": [],
      "source": [
        "for classifier in classifiers:\n",
        "    # get the output layer for this subclassifier\n",
        "    last = classifier.layers[len(classifier.layers) - 1]\n",
        "    print(last, last.name)\n",
        "\n",
        "    # find the corresponding variety dataset\n",
        "    for key, dataset in varieties_datasets.items():\n",
        "        if key == last.name:\n",
        "            x_test, y_test = dataset[\"test\"]\n",
        "            scores = classifier.evaluate(x_test, y_test, verbose=1)\n",
        "            print(\"Test\", scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4302a951887c"
      },
      "source": [
        "### Save the Finer Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a228f0e30d38"
      },
      "outputs": [],
      "source": [
        "n = 0\n",
        "for classifier in classifiers:\n",
        "    classifier.save(\"model-finer-\" + str(n) + \".h5\")\n",
        "    n += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "217172b4d3b1"
      },
      "source": [
        "## Let's do some cascading predictions\n",
        "\n",
        "We will take one random selected image per type of fruit, and:\n",
        "\n",
        "    1. Run the image through the coarse classifier (by fruit).\n",
        "    2. Based on the predicted output, select the corresponding finer classifier (by variety).\n",
        "    3. Run the image through the corresponding finer classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07c8b9c3a306"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Let's make a prediction for each type of fruit\n",
        "for key, dataset in varieties_datasets.items():\n",
        "\n",
        "    # Get the variety test data for this type of fruit\n",
        "    x_test, y_test = dataset[\"test\"]\n",
        "\n",
        "    # pick a random image in the variety datast\n",
        "    index = random.randint(0, len(x_test))\n",
        "\n",
        "    # use the coarse model to predict the type of fruit\n",
        "    yhat = np.argmax(model.predict(x_test[index : index + 1]))\n",
        "\n",
        "    # let's find the class name (type of fruit) for this predicted label\n",
        "    for fruit, label in fruits_classes.items():\n",
        "        if label == yhat:\n",
        "            break\n",
        "\n",
        "    print(\"Yhat\", yhat, \"Coarse Prediction\", key, \"=\", fruit)\n",
        "\n",
        "    # Prediction was correct\n",
        "    if key == fruit:\n",
        "        if len(dataset[\"classes\"]) == 1:\n",
        "            print(\"No Finer Classifier\")\n",
        "            continue\n",
        "\n",
        "        # find the corresponding finer classifier for this type of fruit\n",
        "        for classifier in classifiers:\n",
        "            # get the output layer for this subclassifier\n",
        "            last = classifier.layers[len(classifier.layers) - 1]\n",
        "            if last.name == fruit:\n",
        "                # use the finer model to predict the variety of this type of fruit\n",
        "                yhat = np.argmax(classifier.predict(x_test[index : index + 1]))\n",
        "                for variety, value in dataset[\"classes\"].items():\n",
        "                    if value == np.argmax(y_test[index]):\n",
        "                        break\n",
        "                for yhat_variety, value in dataset[\"classes\"].items():\n",
        "                    if value == yhat:\n",
        "                        break\n",
        "                print(\"Yhat\", yhat, \"Finer  Prediction\", variety, \"=\", yhat_variety)\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b8f537f31d9"
      },
      "source": [
        "### End of Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80b09c1e7696"
      },
      "outputs": [],
      "source": [
        "#     extractfeatures = Model(input=model.input, output=model.get_layer('bottleneck').output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "cascade.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
