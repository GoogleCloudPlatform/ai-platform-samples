{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "qnMpW5Y9nv2l"
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHF9VCProKJN"
      },
      "source": [
        "# TabNet: Attentive Interpretable Tabular Learning\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/ml-on-gcp/blob/master/tutorials/explanations/ai-explanations-tabnet-algorithm.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/ml-on-gcp/tree/master/tutorials/explanations/ai-explanations-tabnet-algorithm.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZzRVxNtH-zG"
      },
      "source": [
        "## Overview\n",
        "\n",
        "AI Platform provides a built-in algorithm based on [TabNet](https://arxiv.org/abs/1908.07442).\n",
        "\n",
        "Learn how to [train and deploy a model with the TabNet built-in algorithm](https://cloud.google.com/ai-platform/training/docs/algorithms/tab-net-start).\n",
        "\n",
        "This tutorial provides the sample code to visualize the explanation of TabNet algorithm with Synthetic_2 (Syn2) data.\n",
        "\n",
        "Syn2 data is described at [Section 4.1 of learning to explain paper](https://arxiv.org/pdf/1802.07814.pdf). The input feature X is generated from a 10-dimensional standard Gaussian. The response variable Y is generated from feature X[3:6] only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su2qu-4CW-YH"
      },
      "source": [
        "### Objective\n",
        "\n",
        "The goal is to provide a sample plotting tool to visualize the output of TabNet, which is helpful in explaining the algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgLXkyHEvTVD"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "Make sure you're running this notebook in a **GPU runtime** if you have that option. In Colab, select **Runtime** --> **Change runtime type**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avDUUQEGTnUo"
      },
      "source": [
        "This tutorial assumes you are running the notebook either in **Colab** or **Cloud AI Platform Notebooks**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2qsxysTVc-l"
      },
      "source": [
        "### Set up your GCP project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a GCP project.](https://console.cloud.google.com/cloud-resource-manager)\n",
        "\n",
        "2. [Make sure that billing is enabled for your project.](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
        "\n",
        "3. [Enable the AI Platform Training & Prediction and Compute Engine APIs.](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component)\n",
        "\n",
        "4. Enter your project ID in the cell below. Then run the  cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "4qxwBA4RM9Lu"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"python_docs_samples_tests\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSy-f05IO4LB"
      },
      "source": [
        "### Authenticate your GCP account\n",
        "\n",
        "**If you are using AI Platform Notebooks**, your environment is already\n",
        "authenticated. Skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZQUrHdXNJnk"
      },
      "source": [
        "**If you are using Colab**, run the cell below and follow the instructions\n",
        "when prompted to authenticate your account via oAuth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9i6oektpgld"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "# If you are running this notebook in Colab, follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "\n",
        "def install_dlvm_packages():\n",
        "    !pip install tabulate\n",
        "\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()\n",
        "    !pip install witwidget --quiet\n",
        "    !pip install tensorflow==1.15.0 --quiet\n",
        "    !gcloud config set project $PROJECT_ID\n",
        "\n",
        "\n",
        "elif \"DL_PATH\" in os.environ:\n",
        "    install_dlvm_packages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT061irlJwkg"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "When you submit a training job using the Cloud SDK, you upload a Python package\n",
        "containing your training code to a Cloud Storage bucket. AI Platform runs\n",
        "the code from this package. In this tutorial, AI Platform also saves the\n",
        "trained model that results from your job in the same bucket. You can then\n",
        "create an AI Platform model version based on this output in order to serve\n",
        "online predictions.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
        "Cloud Storage buckets. \n",
        "\n",
        "You may also change the `REGION` variable, which is used for operations\n",
        "throughout the rest of this notebook. Make sure to [choose a region where Cloud\n",
        "AI Platform services are\n",
        "available](https://cloud.google.com/ml-engine/docs/tensorflow/regions). You may\n",
        "not use a Multi-Regional Storage bucket for training with AI Platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTxmbDg1I0x1"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"[<your-bucket-name>]\"\n",
        "REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsmCk2dwJnLZ"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "160PRO3aJqLD"
      },
      "outputs": [],
      "source": [
        "!gsutil mb -l $REGION gs://$BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyxoF-iqqD1t"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "Import the libraries we'll be using in this tutorial. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEDlLSWK15UL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.cloud import storage\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRVMEU2Qshm4"
      },
      "source": [
        "## Reading a sample TabNet prediction on syn2 data\n",
        "\n",
        "After training and serving your model, you upload the output to Google Cloud Storage. There is a sample TabNet prediction using synthetic data: gs://cloud-samples-data/ai-platform/synthetic/tab_net_output/syn2\n",
        "\n",
        "You can copy this output to your bucket for testing. Running prediction on your own data will generate the output having the same format.\n",
        "\n",
        "Each prediction in TabNet contains **aggregated_mask_values** field. The masks are used to explain the predictions. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7HLNsvekxvz"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://cloud-samples-data/ai-platform/synthetic/tab_net_output/syn2 gs://$BUCKET_NAME\n",
        "\n",
        "# Replace your the BUCKET_NAME and PREDICTION_FILE\n",
        "# BUCKET_NAME = \"[<your-bucket-name>]\"\n",
        "# PREDICTION_FILE = \"[<your-prediction-file>]\"\n",
        "\n",
        "PREDICTION_FILE = \"syn2\"\n",
        "\n",
        "MASK_KEY = \"aggregated_mask_values\"\n",
        "\n",
        "HEADER = [(\"feat_\" + str(i)) for i in range(1, 12)]\n",
        "HEADER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zr6lj66UlMn"
      },
      "source": [
        "### Download and preprocess the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Icz22E69smnD"
      },
      "outputs": [],
      "source": [
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
        "blob = bucket.blob(PREDICTION_FILE)\n",
        "f = blob.download_as_string(client=None).decode(\"utf-8\").strip()\n",
        "predictions = f.split(\"\\n\")\n",
        "predictions[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSrzwuchvcgv"
      },
      "source": [
        "### Parse the mask values in prediction. Then, concatenate the mask values.\n",
        "The output is a matrix having Nxk (N is the number of outputs, k is the size of each mask).\n",
        "Concatenating mask values are used to visualize the feature importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5PIljnYveDN"
      },
      "outputs": [],
      "source": [
        "masks = []\n",
        "for prediction in predictions:\n",
        "    prediction = json.loads(prediction)\n",
        "    masks.append(prediction[MASK_KEY])\n",
        "masks = np.matrix(masks)\n",
        "masks.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV_NEAQwwH0e"
      },
      "source": [
        "## Visualize the mask value matrix. \n",
        "The lighter color indicates more important feature.\n",
        "For example, only features 3-6 are meaningful in prediction output in Syn2 data. In the plot, the column 3-6 have light color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kQz8Q0DsBM7"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 10))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.imshow(masks[:50, :], interpolation=\"bilinear\", cmap=cm.Greys_r)\n",
        "ax.set_xlabel(\"Features\")\n",
        "ax.set_ylabel(\"Sample index\")\n",
        "ax.xaxis.set_ticks(np.arange(len(HEADER)))\n",
        "ax.set_xticklabels(HEADER, rotation=\"vertical\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F2g4OjbJ3gZ"
      },
      "source": [
        "If your Cloud Storage bucket doesn't contain any other objects and you would like to delete it, run `gsutil rm -r gs://$BUCKET_NAME`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0UXLWaBJnrY"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "To learn more about TabNet, check out the resources here.\n",
        "\n",
        "* [TabNet: Attentive Interpretable Tabular Learning](https://arxiv.org/abs/1908.07442)\n",
        "* [https://arxiv.org/abs/1908.07442](https://cloud.google.com/ai-platform/training/docs/algorithms?hl=en) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ai-explanations-tabnet-algorithm.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
